# IaSQL

<h2 align="center">
Infrastructure as SQL
</h2>

### Local Development

Set your .env file based on the values from `src/config.ts`, make sure docker is installed locally and then run

```
docker-compose up
```

which will bring up the postgres engine and node.js server.

### Architecture

This is a quick note on the general architecture we're thinking of taking. It will evolve over time and we'll replace this short blurb with something more formal later on.

#### This is an eventually-consistent design where the SQL tables are the source of truth.

This means that the state that users create in the SQL tables is what things will be pushed towards, *not* reading the state from the cloud and exposing it to end users for querying. It's eventually consistent so multiple changes can be queued up without latency on the user's side and any difference between reality and what's in the tables will be treated as an issue to be corrected and a cloud migration to perform.

There are a couple of places (like security group IDs) where we can't avoid the ID being generated by the cloud instead of ourselves within postgres. These will need to be nullable columns that we eventually fill in once the security group is created during the creation process. Similarly, things that depend on other things with nullable columns will fail if that column is still null, so `is not null` checks should be included in the queries involving them, though this isn't a hard requirement, as it being null will just cause the API call to fail (but better to not do that when we know it won't work in the first place).

#### Impedance mismatch between APIs and SQL Schemas should be minimized

This means the tables should be detail-oriented, not high-level, so every little property can be represented appropriately. Parts of an API that allow a variable number of inputs imply a separate table and likely a join table in between. This can make some things very complicated to express and we should create views and stored procedures to help out here.

#### Users get their own "database" inside of our database

Currently thinking that each cluster should be treated as a specially-named database that we then run a `.sql` template to create the required tables, and then give the users access to that database with write permission (and new table creation, but somehow block deletion or alteration of the templated tables, if possible). At first these could all be inside of a single RDS instance (so we get snapshotting "for free") and later on we could shard by database name, so we stay horizontally scalable.

This is assuming no one user is able to overload the Postgres database. We may need to isolate an RDS instance per user if that is not the case, but I cannot imagine how you would do that with a database to manage your infrastructure?

We can then make the job to poll the various databases an actual cron job and then schedule work for any database that has a difference between representation and reality. For now we can just manually trigger that per database name with a simple `/check/<dbname>` HTTP request on our test server, which gives us the added benefit of being able to pause changes to our test AWS accounts if/when it doesn't do what we expected and we want to figure out why.

The actual execution requires access to credentials. While we're testing we can just use the local credentials on our machines, but in reality, we'll need to use something like the AWS Secrets Manager to hold on to them. Later on we may make our own "vault" service to tackle this problem because that service gets expensive fast, especially with how we're proposing to use it.
