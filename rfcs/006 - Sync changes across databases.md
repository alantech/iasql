# 006 - Sync changes across databases RFC

### Proposed

2022-12-16

### Accepted

YYYY-MM-DD

#### Approvers

- David Ellis <david@iasql.com>
- Yolanda Robla <yolanda@iasql.com>
- Alejandro Guillen <alejandro@iasql.com>
- Mohammad Pabandi <mohammad@iasql.com>

### Implementation

- [ ] Implemented: [One or more PRs](https://github.com/iasql/iasql-engine/some-pr-link-here) YYYY-MM-DD
- [ ] Revoked/Superceded by: [RFC ###](./000 - RFC Template.md) YYYY-MM-DD

## Author(s)

- Luis Fernando De Pombo <luisfer@iasql.com>

## Summary

An IaSQL database connects to a cloud account and automatically backfills it with what is already in the cloud account during the initial onboarding and keeps it up to date over time. However, once you import your staging *and* production cloud accounts to two different databases it is not clear how to make changes to both or keep them in sync. The common workflow is to make changes to your staging deployment and then replicate the changes to your production deployment. One of the appeals of SDK-based IaC tools like Pulumi is that you can apply the blueprint like a hammer with some parametrization. This is also possible in Terraform with HCL, but it is a bit more clunky.

We have leaned deeper into the infrastructure as data workflow by favoring two-way mode with transactions over IaC’s apply. This plays to our strengths and provides a compelling workflow to manage infrastructure. However, we need a good story to import or replicate changes from one database to the other since most people manage staging and production as separate cloud accounts.

Two important requirements to keep in mind are:
1. Being able to account for the fact that most of our joins are done using auto-incremented IDs which makes them different in every database.
2. Users might want to exclude certain resources from the import workflow. In other words, there might be resources in staging that people don't want to replicate in production and vice versa. This requirement can be sidestepped initially, but whatever design we pick should be able to support this down the line.

## Proposal

There are too many edge cases around our data model and different kinds of staging->production arrangements companies might have (differences in capacity and secrets are a given, plus the two environments could be in different regions altogether) to try to reliably perform an import from one database to another automatically. The alternatives considering automatic workflows would fail or require manual intervention the majority of the time. The expectation for the workflow we set forth should then be that the user will still need to provide a decent amount of manual input.

The IaSQL audit log table is timestamped and looking at the records from a given point in time for a staging database will give users most of the information they need to be able to replicate the changes in production. This proposal is grounded on that fact and seeks to make that workflow as smooth as possible by creating a feature that generates SQL from the audit log from a given point in time. The given point in time for this use case would be the last time staging and production were synced. The generated SQL will then be massaged and manually run by the user in production via a PostgreSQL client or a migration within a plain SQL migration system for teams that want to code review infrastructure changes. The IaSQL audit log is ordered chronologically and the SQL generated by a `iasql_get_sql_since()` function should not cause duplicate records or FK relation problems even if the expectation is that the generated SQL should be massaged.

It is worth pointing out that `INSERT` statements that are referencing an auto-generated ID should generate the SQL with a sub-query that `SELECT`s on the @cloudId column's value, if available. It should be immediately clear to the user that they need to substitute that string with the production equivalent ID, and in some situations where the cloud ID is a user-provided string, it may not need any changes.

## Alternatives Considered

There are several types of solutions to replicate staging infrastructure changes in production.

### 1. Dump a database and import the dump into another database

An `export` route in the engine implemented using `pgdump` with logic to attempt to make it generic like excluding `aws_account` from the dump and so on. The dump is then intended to be passed into an `import` route for another database. `import` was deprecated for the time being due to the sheer amount of special-casing, which compounded per module, that had to be built within the functionality of export and import.

### 2. Sync a database to a different cloud account than the one it is connected to

An IaSQL function that takes the alias of another dataabse owned by the same user as input. `iasql_import(‘staging’)` will return the same data structure as `iasql_commit` or `iasql_preview`. This function can reuse parts of the mappers and existing IaSQL functions to run diffs across two different databases or accounts. There could have an optional `dry_run` parameter or another function to preview the changes: `iasql_preview_import(‘staging’)` or `iasql_import(‘staging’, true)`.

The steps to replicate recent database/account A changes in database/account B when calling `iasql_import('A')` from within database B:
1) Regular sync database A to cloud account A
2) Regular sync database B to cloud account B
3) New import sync functionality where database B is pointed to cloud account A directly

The new import sync functionality described in #3 would expand the mapper definitions to include a new `import` function and laxer equality function for each module.

### 3. Interactive `git rebase` style sync

Similar to option 2, but when conflict arises prompt the user to handle the merge conflicts between the two cloud accounts or databases interactively. The PostgreSQL REPL doesn't allow interactive input so that would have to happen using a two-phase process via an interim table or the dashboard. This option requires a lot of resources to implement out of the gate. The current proposal and if this workflow proves to be primordial to users we can eventually prioritize it.

### 4. Use existing PostgreSQL data synchronization tools

There is a breadth of tools to keep two databases in sync. However, they are not enough to satisfy our requirements for this problem because the data should not be copied over exactly as-is. We have cloud-generated IDs as columns in a lot of tables that are specific to a resource in each account like an EC2 instance id.

### 5. Emulate a declaration via ORMs with introspection + Upserts

Lean on ORMs with introspection and upserts to generate code akin to an SDK-like IaC declaration. This is not a viable option. Deletions are not truly idempotent as IaSQL has no way of knowing what upserts were added or removed from the declaration script.

## Expected Semver Impact

This would be considered a minor version bump as it would only involve the addition of an IaSQL function.

## Affected Components

The IaSQL audit table might need additional information added to it to be able to recreate the SQL changes.

## Expected Timeline

It should be possible to implement an `iasql_get_sql_since`-like function in 2-4 days.