---
slug: why-sql-for-infrastructure
title: Why SQL is right for Infrastructure Management
authors: [dfellis]
---

# Why SQL is right for Infrastructure Management

Infrastructure is the heart of your company. Without it, nothing can actually be done and there'd be no reason for customers to fork over cash. For software companies that infrastructure is the software that its engineers directly write, and usually the cloud infrastructure and services it runs on top of and integrates with.

In this post, we will geek out on various software abstractions and data structures, tools used by professionals of various sorts, and dig into the pros and cons of these with respect to cloud infrastructure management in particular. We'll see that while SQL has its own warts, it is the "least worst" of all of the options out there.

## Following these instructions is imperative

The simplest way to define how to set something up is to write up a list of instructions to follow, in order, to build whatever infrastructure you're dealing with, whether its the instructions on how to build a restaurant or an AWS Fargate cluster. This list of steps to process (with a LISt Processor, or [LISP](https://en.wikipedia.org/wiki/Lisp_%28programming_language%29), if you will ðŸ˜‰), which can include instructions to repeat or skip over steps based on conditions you have run into, is called [imperative programming](https://en.wikipedia.org/wiki/Imperative_programming) in the software world.

For your cloud infrastructure, this is similar to using the [AWS SDK](https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/) and directly calling the various methods, checking their results and eventually arriving at the desired infrastructure. It is *also* like following a step-by-step guide clicking through the various AWS console UI elements to set up your infrastructure, like in [this guide](https://towardsdatascience.com/deploy-your-python-app-with-aws-fargate-tutorial-7a48535da586). The latter may not be automated, to you, but your company executives don't care how the infrastructure building was accomplished as long as it was done quickly, cheaply, and reliably, and you know they always want all three. ðŸ˜‰

Imperative infrastructure management works *well* for initial setup of new infrastructure. There's nothing there to interfere with it, so you can just write the "happy path" and get it working. And if that fails, you can just tear it all down and start all over again if that's cheap, which it is for cloud infrastructure (though not for building a restaurant), so the [cyclomatic complexity](https://en.wikipedia.org/wiki/Cyclomatic_complexity) of the code you write is low and everyone can follow along with it.

However, once you need to make changes to your existing infrastructure, that original code you wrote is more than likely useless to you. To get from the *current* state of your infrastructure to your *desired* state, you need to call different APIs than you did before, and its much riskier to make a mistake because this infrastructure is already in use.

<!-- TODO: This section should be expanded with example code that does a relatively simple task. Something that we can use across all of the sections of this post to better emphasize the point we're making -->

## Declare your intentions at once

When the desired state is relatively simple to define and the mechanism to reach that state is not that important, writing up a declaration of what is needed and letting something/someone else deal with it is the most logical abstraction. This would be like drafting up the architectural draft for your new restaurant and paying a contracting company to actually build it, or [writing HTML and letting a web browser render it](https://en.wikipedia.org/wiki/Declarative_programming#Domain-specific_languages), or writing a [Terraform HCL](https://github.com/hashicorp/hcl) file and letting the Terraform CLI tool `apply` it. This is called [declarative programming](https://en.wikipedia.org/wiki/Declarative_programming) in the software world, and has many advantages (and a few disadvantages!) for cloud infrastructure management.

In declarative programming you have some initial state and in comparatively dense and high-level declarative code define the desired state. In many use-cases (like web browsers and sometimes for restaurant-building contractors) the initial state is "blank" and the engine that transforms the declarative code into imperative operations can often be a relatively straightforward [interpreter](https://en.wikipedia.org/wiki/Interpreter_%28computing%29) walking the [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) of the declarative code.

Infrastructure management *generally* is not that straightforward. Changes to infrastructure require in-place mutations of the current state. A full [blue/green deployment](https://en.wikipedia.org/wiki/Blue-green_deployment) of the entirety of your production infrastructure is very expensive, requiring all resource costs to be doubled, and deployments to require some amount of downtime for users to swap over and state to be resynchronized. Particularly for databases this approach is essentially impossible as there is too much state to swap.

So declarative programming for infrastructure, also known as [Infrastructure as Code](https://en.wikipedia.org/wiki/Infrastructure_as_code), must take the existing state and generate the imperative operations to perform based on the differences between the existing state and the declared desired state. This is like a contracting company being given an architecture draft for a new restaurant and being told to remodel an existing commercial space (maybe it was also a restaurant, maybe it was a clothing store, etc) and the contracting company figuring out what needs to be torn down first, what can be re-used, and what needs to be built new.

This diffing of original and desired state can be resolved several ways. The contracting company could spend a lot of time inspecting the existing commercial space to find absolutely every piece that can be re-used, removing them and setting them aside with the materials that need to be purchased, then rework the interior walls, and build everything from scratch, or it could decide to tear everything out back into an empty space and rebuild from scratch (like what your web browser does between web pages), or perhaps you need to keep the space mostly usable for customers, minimizing disruption to the current operations while things are changed. This last case is what infrastructure management tools need to tackle your infrastructure with the least amount of downtime or no downtime at all, if you're *careful* with it.

How can you "careful" with declarative programming tools, if you don't have direct control over what they do? Terraform does this with a [plan](https://developer.hashicorp.com/terraform/cli/commands/plan) command, which performs the diffing of current and desired state and reports back to you the operations it expects to execute to do so. Terraform will tell you when a change it intends to make is going to provision new resources, alter existing resources, drop resources, and *replace* resources. That last one is particularly annoying when it shows up because it means the change you want to perform can only be done by dropping it and recreating it with the new configuration.

When you see steps where Terraform plans to drop or replace resources, you can decide if that's actually alright, or if it will negatively impact your business during the deployment, and then you can abort and define an intermediate state to first transition to, usually creating a new resource without dropping the old one, then do whatever operation is necessary to move internal state to it, then continue by deleting the old resource. This is like checking up on your contracting company before they start doing their work to make sure they don't do anything strange you don't want, and sometimes needing to handhold them through details of your business to come up with the new plan of action.

Until cloud resource management is as quick to execute as a webpage render where state changes can be done faster than a human can respond, this sort of hand-holding is necessary for live infrastructure with uptime guarantees. Declarative programming, at least for cloud infrastructure management, is a [leaky abstraction](https://en.wikipedia.org/wiki/Leaky_abstraction) over the imperative operations that need to be executed.

The Terraform HCL files don't have the prior state encoded into them, nor does it depend on being stored within a git repository to provide that prior state, so how does Terraform get that initial state to operate on? Terraform maintains an [internal statefile](https://developer.hashicorp.com/terraform/language/state) to perform the diffing against. It has a mechanism to [refresh that state](https://developer.hashicorp.com/terraform/cli/commands/refresh), but being a JSON blob with poor typing, can [become corrupted, requiring manual intervention](https://faun.pub/cleaning-up-a-terraform-state-file-the-right-way-ab509f6e47f3).

Why does Terraform need this JSON-based statefile when it has the much cleaner HCL format that you use as a developer? This is because HCL, as a language that provides affordances to the developer's own intuition on how to structure their representation of their infrastructure, does not have a [canonical form](https://en.wikipedia.org/wiki/Canonical_form) to make these comparisons with. Terraform must first pre-process the HCL into an internal data structure which it can then generate a [diff](https://en.wikipedia.org/wiki/Diff) that can then be used to determine the operations to perform. The JSON-based statefile is likely a very close representation of this internal data structure, and manual editing of it is highly discouraged because the details of it likely vary from release to release with an internal migration mechanism performed on upgrade of the Terraform CLI.

Needing to learn Terraform's HCL language to make infrastructure changes has been cited as a [weakness](https://www.pulumi.com/why-pulumi/) that can be mitigated by wrapping it in the syntaxes more familiar to the user like [Terraform CDK](https://developer.hashicorp.com/terraform/cdktf), [Pulumi](https://www.pulumi.com), or [AWS CDK](https://docs.aws.amazon.com/cdk/v2/guide/home.html). This *is* a weakness, but we believe that the HCL-to-Statefile transformation being [surjective](https://en.wikipedia.org/wiki/Surjective_function) instead of [bijective](https://en.wikipedia.org/wiki/Bijection) is actually the bigger issue.

<!-- TODO: This section could use actual HCL code, and ideally some way you can trigger a corruption of the statefile vs AWS's actual state -->

## The Objective is Bi- hmmmm....

A bijective function has a one-to-one mapping of all state in one set with all state in another set. Both representations are equivalent (given the appropriate transform functions), both sets (of possible cloud states) are the same size (conceptually), and for any one particular state in one set there is exactly one state in the other set. Programming Languages don't fit the bill here, as was demonstrated earlier, but what does? What, exactly, defines your cloud resources in the most minimal way?

The answer is ~~~[water vapor](https://en.wikipedia.org/wiki/Cloud)~~~ [Entities](https://en.wikipedia.org/wiki/Entity#In_computer_science). Each cloud resource has some unique identifier and a set of properties that configure it. Some of those properties can be relations or dependencies on other cloud resources. The ordering of the entities does not matter, so long as the dependencies are explicitly defined to make determination of the order of operations possible.

This means the representation of your cloud resources should be *data*, not code. Particularly, it should be relational data.

Since your infrastructure is actually data, just about any data format *could* be used to store it, as demonstrated by Terraform's usage of JSON under-the-hood. Some will require more application-level guarantees on top of the data format to achieve all of the necessary components, however. For instance JSON does not have any native way to represent *references* to other JSON objects that are not wholly contained within the object in question, so you would need to define a way to represent them and enforce it within your application. [YAML does support them via tags](https://yaml.org/spec/1.2.2/#24-tags) but being a markup language has multiple equivalent representations and is therefore not suitable for this purpose (without a strict linter to reduce it back down to a canonical form). There are also [binary formats that can encode references](https://capnproto.org/language.html#dynamically-typed-fields) with [SQLite's file format](https://www.sqlite.org/cli.html) arguably being the most prolific.

SQL immediately stands out here because it was designed for making [relational algebra](https://en.wikipedia.org/wiki/Relational_algebra), the other side of the [Entity-Relationship model](https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model), accessible. There are likely more people who know SQL than any programming language (for IaC) or data format you could choose to represent your cloud infrastructure, because non-programmers know it, as well, and there is an entire ecosystem of useful functionality you gain "for free" by using a SQL representation than just about any format out there. Furthermore, a powerful SQL engine like the open source [PostgreSQL](https://postgresql.org) provides tools capable of elevating the infrastructure management *experience* beyond what IaC can do today.

- By defining [foreign key relations](https://www.postgresql.org/docs/current/tutorial-fk.html) between tables, the database can immediately inform you if you have dependencies that must be created before you can create the resource you desire.
- By defining [unique, not-null, and check constraints](https://www.postgresql.org/docs/current/ddl-constraints.html) on top of a [rich type system](https://www.postgresql.org/docs/current/datatype.html) the database can prevent you from inserting faulty data to a greater degree than even Rust, as the constraints can be against the live state of your infrastructure itself.
- By being in a database, you can answer questions about your infrastructure via queries, and in the case of security vulnerabilities or expensive misconfigurations you can update that state across the board at the same time.
- By being a bijective relationship with your cloud, you can re-synchronize the database with your cloud at any time, avoiding statefile issues by never getting too out-of-date, and being more difficult to corrupt.
- By defining [trigger functions](https://www.postgresql.org/docs/current/sql-createtrigger.html#SQL-CREATETRIGGER-EXAMPLES) an [audit log](https://en.wikipedia.org/wiki/Audit_trail) can be maintained, which can keep track of who made what cloud changes and when they did.
- Other trigger functions can be added to automatically re-insert deleted records for automated [Chaos Engineering](https://en.wikipedia.org/wiki/Chaos_engineering) recovery.
- [Snapshotting](https://en.wikipedia.org/wiki/Snapshot_%28computer_storage%29) could be used to quickly revert all infrastructure changes without hidden state (eg, the configuration of your load balancers, but not the data within your own databases).
- By having a standardized protocol to interface with the database, you can:
  - Perform operations on it via scripts and the [`psql` CLI](https://www.postgresql.org/docs/current/app-psql.html) tool.
  - Integrate it into your application itself with a [postgres client library](https://node-postgres.com/) for application-driven infrastructure management (like provisioning sharded resources for a client that wants isolation).
  - Connect to it with a [SQL IDE](https://www.jetbrains.com/datagrip/features/postgresql/) for outage mitigation or inspection in a tabular (Excel-like) view.
  - Connect it to a [graphical dashboard](https://grafana.com/docs/grafana/latest/datasources/postgres/) for live visualization of your infrastructure.
  - Connect it to a [low code tool](https://docs.retool.com/docs/postgresql-integration) for rapid response dashboards for your infrastructure with buttons you can tackle known outage vectors near-instantly.

## SQL is the best option for Infrastructure Management

There are negatives to representing your infrastructure as SQL, of course, as there is no perfect solution for all situations, but we believe IaSQL is a superset versus IaC in all but one category.

- SQL is an old, irregular language to work with, but it is better known than HCL and we already have a Pulumi/CDK in the form of every ORM with introspection (like [Javascript's Prisma](https://www.prisma.io/docs/concepts/components/introspection), [Python's Django](https://docs.djangoproject.com/en/4.1/howto/legacy-databases/), [Go's XO](https://github.com/xo/xo) etc) and QueryBuilder ([LINQ](https://learn.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/), [Knex](https://knexjs.org/), etc) in whatever programming language you prefer.
- Peer review of changes is *different* versus IaC. [Migration tools](https://en.wikipedia.org/wiki/Schema_migration) *can* be used to approximate the IaC review process, with the CI system wrapping the migration SQL in an [IaSQL transaction](/docs/transaction) and previewing the operation, but since IaSQL transactions are intentionally *not* actual Postgres transactions, you can simply make the proposed infrastructure changes in the database within an uncommitted IaSQL transaction and allow your peers to inspect/review the database state and call the commit, with the audit log keeping track of the change history for you.
- Database schemas can be overwhelming, and a schema accurately representing *all* of AWS would be dizzying. HCL and other IaC tools let you elide parts of AWS via a module system, so we have implemented our own [module system](/docs/module) on top of Postgres inspired equally by programming language module systems and Linux distro package managers.
- IaC tools have higher-level modules for even simpler, cookie-cutter use-cases, so we [did the same](/docs/low-level-vs-high-level) in IaSQL.
- IaSQL is declarative like IaC, so the leaky abstraction can still impact things, but [using transactions](/docs/transaction) you can enqueue changes and preview what actions the engine will take before commiting to it (or rolling it back). Going beyond that and acknowledging that sometimes you need to directly work in the lower abstraction layer, IaSQL exposes optional [raw SDK access](https://iasql.com/docs/modules/aws/aws_sdk/) within the database to allow for
- As IaSQL is able to both push changes from the database to the cloud and pull changes from the cloud to the database versus the one-way push from HCL that Terraform provides, you can make changes directly in the AWS console, then inspect the audit log to see what SQL records are necessary and automatically generate all of the rest of the resources you need.
- IaSQL makes your infrastructure *accessible* to a much large portion of your company than IaC tools can. Data Scientists who know SQL could help with the provisioning of their own batch processing code, EngSec can query *all* company infrastructure for security vulnerabilities and propose changes to improve things, Business Analysts in Growth teams can query actual traffic information from the live infrastructure (with read-only AWS credentials, of course), Finance auditors can query your infrastructure joined on pricing data and figure out *accurate* expense reporting per division, and DevOps can run queries joined on CloudWatch utilization stats to automatically identify overprovisioned services and create recommended auto-load scaling configuration changes. Tons of "not-developer" and "developer-adjacent" roles that can take over a lot of the ancillary burden of maintaining a production system.
- But IaSQL is much newer than the IaC tools. We have coverage at the time of writing for 25 different AWS services, but that is admittedly far from complete. IaC tools also have cloud resources they cannot represent, but it is a much smaller percentage.

<!-- TODO: Not sure about all of these lists at the end. Should I turn it all into a ton of paragraphs? -->

IaSQL is [currently in beta](/blog/beta) and can be used locally with [`docker`](https://hub.docker.com/r/iasql/iasql) or via our [SaaS](https://app.iasql.com). Even if you're currently using an IaC like Terraform, IaSQL can re-sync with your cloud on external changes to the infrastructure, so it won't step on the toes of any service you're managing with it, so feel free to try it out on a greenfield project, or just monitor what Terraform is doing to your infrastructure via the audit log. And if you're not using an IaC tool because trying to hand-write HCL representing your current cloud infrastructure is too daunting, definitely give IaSQL a try, when an AWS module is installed, it automatically syncs the state of your infrastructure into the database at that time, and you can begin management immediately.

<!-- TODO: Better closing paragraph, I think. It feels a bit flat. Also, there should probably be images/diagrams in this blog post, related to the examples, screenshots of the various tools I suggested could be connected to IaSQL, etc, maybe even a joke reference to something like https://github.com/centerofci/mathesar -->
